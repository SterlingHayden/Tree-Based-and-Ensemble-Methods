{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Methods and Ensemble Methods\n",
    "Sterling Hayden  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "1. 'Hitters' Data is a dataset with baseball player salaries and numbers of features\n",
    "associated with the players. We will split the data into 80-20 % training and validation\n",
    "data.  \n",
    "2. Fit a Decision Tree with Number of leaf nodes 5, 10, 15, 20, .... 100. For each model\n",
    "compute training error and validation errror (MSE). For each Decision Tree with different\n",
    "numbers of leaf nodes plot numbers of lead nodes vs MSE for training and validation\n",
    "dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Alan Ashby</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alvin Davis</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andre Dawson</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andres Galarraga</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alfredo Griffin</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  \\\n",
       "Player                                                                          \n",
       "-Alan Ashby          315    81      7    24   38     39     14    3449    835   \n",
       "-Alvin Davis         479   130     18    66   72     76      3    1624    457   \n",
       "-Andre Dawson        496   141     20    65   78     37     11    5628   1575   \n",
       "-Andres Galarraga    321    87     10    39   42     30      2     396    101   \n",
       "-Alfredo Griffin     594   169      4    74   51     35     11    4408   1133   \n",
       "\n",
       "                   CHmRun  CRuns  CRBI  CWalks League Division  PutOuts  \\\n",
       "Player                                                                    \n",
       "-Alan Ashby            69    321   414     375      N        W      632   \n",
       "-Alvin Davis           63    224   266     263      A        W      880   \n",
       "-Andre Dawson         225    828   838     354      N        E      200   \n",
       "-Andres Galarraga      12     48    46      33      N        E      805   \n",
       "-Alfredo Griffin       19    501   336     194      A        W      282   \n",
       "\n",
       "                   Assists  Errors  Salary NewLeague  \n",
       "Player                                                \n",
       "-Alan Ashby             43      10   475.0         N  \n",
       "-Alvin Davis            82      14   480.0         A  \n",
       "-Andre Dawson           11       3   500.0         N  \n",
       "-Andres Galarraga       40       4    91.5         N  \n",
       "-Alfredo Griffin       421      25   750.0         A  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Dataset and view some\n",
    "df=pd.read_csv(\"Hitters.csv\",index_col=0).dropna()\n",
    "df.index.name = 'Player'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 19)\n"
     ]
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "\n",
    "#Split feature and response and replace categorical features with numerical dum\n",
    "y = df.Salary\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float')\n",
    "# Define the feature set X.\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into 80-20 % training and validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Decision Tree with Number of leaf nodes = 5, 10, 15, 20, ... 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_leaf: 5, train_MSE: 83487.78103289659, test_MSE: 65264.8917396763\n",
      "num_leaf: 8, train_MSE: 59178.41722101653, test_MSE: 55049.53294288881\n",
      "num_leaf: 12, train_MSE: 42123.62142117608, test_MSE: 55884.30184611296\n",
      "num_leaf: 16, train_MSE: 32103.00520555323, test_MSE: 59834.87706192988\n",
      "num_leaf: 20, train_MSE: 23030.276059594475, test_MSE: 83123.09752191976\n",
      "num_leaf: 24, train_MSE: 18123.63521510096, test_MSE: 85400.81806379478\n",
      "num_leaf: 28, train_MSE: 14412.47919722019, test_MSE: 84581.25038135794\n",
      "num_leaf: 32, train_MSE: 10820.12864793139, test_MSE: 78860.85438093558\n",
      "num_leaf: 36, train_MSE: 8291.327600527131, test_MSE: 75869.61616616652\n",
      "num_leaf: 40, train_MSE: 6430.743829992893, test_MSE: 73480.92570757102\n",
      "num_leaf: 44, train_MSE: 5015.097584447165, test_MSE: 75213.81087687763\n",
      "num_leaf: 48, train_MSE: 4045.6460659693194, test_MSE: 76126.41913450633\n",
      "num_leaf: 52, train_MSE: 3127.363187750255, test_MSE: 76364.28142053106\n",
      "num_leaf: 56, train_MSE: 2501.5409841228793, test_MSE: 76276.7181520635\n",
      "num_leaf: 60, train_MSE: 1952.0014171034352, test_MSE: 77115.52452027932\n",
      "num_leaf: 64, train_MSE: 1525.5848500091006, test_MSE: 76344.7053675885\n",
      "num_leaf: 68, train_MSE: 1196.3645973634657, test_MSE: 75743.8599142342\n",
      "num_leaf: 72, train_MSE: 918.8440063581481, test_MSE: 73623.14504274583\n",
      "num_leaf: 76, train_MSE: 738.2801172561608, test_MSE: 73629.28993876165\n",
      "num_leaf: 80, train_MSE: 610.2009505894943, test_MSE: 73649.26582974698\n",
      "num_leaf: 84, train_MSE: 510.71552466290694, test_MSE: 73555.0272946314\n",
      "num_leaf: 88, train_MSE: 416.0040632507558, test_MSE: 73534.23899957485\n",
      "num_leaf: 92, train_MSE: 338.2920598492063, test_MSE: 73550.02295662211\n",
      "num_leaf: 96, train_MSE: 270.24741699206345, test_MSE: 75038.66123754455\n",
      "num_leaf: 100, train_MSE: 217.7183601134921, test_MSE: 75850.6405942023\n"
     ]
    }
   ],
   "source": [
    "num_leaf = np.linspace(5,100, 25).astype(int)\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "for i in num_leaf: \n",
    "    regressor = DecisionTreeRegressor(random_state=0,max_leaf_nodes=i)\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    train_error = mean_squared_error(y_train,y_pred_train)\n",
    "    train_MSE.append(train_error)\n",
    "    y_pred_test = regressor.predict(X_test)\n",
    "    test_error = mean_squared_error(y_test, y_pred_test)\n",
    "    test_MSE.append(test_error)\n",
    "    print(f\"num_leaf: {i}, train_MSE: {train_error}, test_MSE: {test_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num_leaf: 8, Best test_MSE: 55049.53294288881\n"
     ]
    }
   ],
   "source": [
    "best_num_leaf = num_leaf[np.argmin(test_MSE)]\n",
    "best_test_MSE = min(test_MSE)\n",
    "# best leaf # based on test mse\n",
    "print(f\"Best num_leaf: {best_num_leaf}, Best test_MSE: {best_test_MSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging, Random Forest, and Boosting for Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430  58.7  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "5  394.12   5.21  28.7  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "df=pd.read_csv(\"boston.csv\").dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 13)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split dataset\n",
    "X=df.iloc[:,:-1].values\n",
    "y=df.MEDV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=88)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomsearchCV Parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Bagging one of the hyperparameter we can tune are numbers of trees (n_esti\n",
    "# Numbers of samples to use in bootstraping (max_samples), etc. \n",
    "br = BaggingRegressor(random_state = 0)\n",
    "br_params = {\n",
    " 'max_samples': [0.5, 0.7], # Fraction of Data to use in Bootst\n",
    " 'n_estimators': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 100], #\n",
    " }\n",
    "# Create a GridSearch object\n",
    "br_gs = GridSearchCV(br, param_grid = br_params, cv = 3, verbose = 1, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 22 candidates, totalling 66 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=BaggingRegressor(random_state=0), n_jobs=1,\n",
       "             param_grid={&#x27;max_samples&#x27;: [0.5, 0.7],\n",
       "                         &#x27;n_estimators&#x27;: [2, 5, 10, 20, 30, 40, 50, 60, 70, 80,\n",
       "                                          100]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=BaggingRegressor(random_state=0), n_jobs=1,\n",
       "             param_grid={&#x27;max_samples&#x27;: [0.5, 0.7],\n",
       "                         &#x27;n_estimators&#x27;: [2, 5, 10, 20, 30, 40, 50, 60, 70, 80,\n",
       "                                          100]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: BaggingRegressor</label><div class=\"sk-toggleable__content\"><pre>BaggingRegressor(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingRegressor</label><div class=\"sk-toggleable__content\"><pre>BaggingRegressor(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=BaggingRegressor(random_state=0), n_jobs=1,\n",
       "             param_grid={'max_samples': [0.5, 0.7],\n",
       "                         'n_estimators': [2, 5, 10, 20, 30, 40, 50, 60, 70, 80,\n",
       "                                          100]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Bagging Regressor for all parameter combinations we declared\n",
    "br_gs.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 0.7, 'n_estimators': 80}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Best HyperParameters for Bagging and use these params\n",
    "br_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error is : 3.1358573214285728\n",
      "Validation error is : 13.72869204905064\n",
      "Out of sample error: 0.8388234522720248\n"
     ]
    }
   ],
   "source": [
    "# Create Bagging Regressor with Best params and fit with training data\n",
    "best_br = BaggingRegressor(n_estimators = 80, max_samples = 0.7, oob_score=True)\n",
    "best_br.fit(X_train,y_train)\n",
    "# Predict on Train and Test Data\n",
    "y_pred_train = best_br.predict(X_train)\n",
    "y_pred_test = best_br.predict(X_test)\n",
    "# Compute Train and Test and OOS Error\n",
    "train_MSE = mean_squared_error(y_train, y_pred_train)\n",
    "test_MSE = mean_squared_error(y_test, y_pred_test)\n",
    "OOS_error = best_br.oob_score_\n",
    "print(\"Training error is :\",train_MSE)\n",
    "print(\"Validation error is :\",test_MSE)\n",
    "print(\"Out of sample error:\",OOS_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Error:** This is the error calculated on a separate dataset, known as the validation set. It is used during the model development process to tune hyperparameters and assess model performance. The validation set is different from the training set but is still part of the same dataset. A validation error helps in selecting the best hyperparameters and detecting early signs of overfitting.  \n",
    "  \n",
    "**Out of Sample Error (Test Error):** This error is calculated on a dataset that the model has never seen during training or model development. It is a measure of the model's generalization performance and its ability to make accurate predictions on new, unseen data. The out-of-sample error is often considered the most important error metric because it reflects how well the model is likely to perform on real-world, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
